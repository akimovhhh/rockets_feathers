{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# USDA Data Extraction\n",
    "\n",
    "This notebook extracts public data from USDA APIs (NASS and AMS) for egg market analysis.\n",
    "\n",
    "**Data Sources:**\n",
    "- NASS QuickStats API: Feed prices (corn, soybeans), poultry statistics\n",
    "- AMS MARS API: Wholesale egg prices\n",
    "\n",
    "**Output Tables:**\n",
    "- `COST_SB_US_MONTHLY`: Soybean prices ($/metric ton)\n",
    "- `COST_CORN_US_MONTHLY`: Corn prices ($/metric ton)\n",
    "- `EGG_PROD_DOZ_MONTHLY`: Egg production (dozen)\n",
    "- `LAYER_INV_MONTHLY`: Layer inventory (head)\n",
    "- `LOSS_DTH_RENDER_MONTHLY`: Layer losses (head)\n",
    "- `WHOLESALE_PRICE_WEEKLY`: Weekly wholesale egg prices by region\n",
    "- `WHOLESALE_PRICE_MONTHLY`: Monthly wholesale egg prices by region\n",
    "- `EGG_STAT_MONTHLY`: Combined monthly statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Imports and Configuration\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "import re\n",
    "\n",
    "import duckdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API keys\n",
    "load_dotenv(os.path.expanduser(\"~/.config/mysecrets/env\"))\n",
    "NASS_KEY = os.environ[\"NASS_KEY\"]\n",
    "AMS_KEY = os.environ[\"AMS_KEY\"]\n",
    "\n",
    "# API endpoints\n",
    "NASS_BASE = \"https://quickstats.nass.usda.gov/api\"\n",
    "AMS_BASE = \"https://marsapi.ams.usda.gov/services/v1.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "constants",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Constants\n",
    "# =============================================================================\n",
    "\n",
    "# Physical constants (document units and sources)\n",
    "LB_PER_BUSHEL_SOY = 60.0                    # USDA standard weight\n",
    "LB_PER_METRIC_TON = 2_204.622_621_85        # Exact SI definition\n",
    "BUSHELS_PER_METRIC_TON_SOY = LB_PER_METRIC_TON / LB_PER_BUSHEL_SOY  # ≈ 36.744\n",
    "\n",
    "LB_PER_BUSHEL_CORN = 56.0\n",
    "BUSHELS_PER_METRIC_TON_CORN = LB_PER_METRIC_TON / LB_PER_BUSHEL_CORN  # ≈ 39.369\n",
    "\n",
    "# Month mappings for NASS API responses\n",
    "MONTH_MAP: dict[str, int] = {\n",
    "    \"JAN\": 1, \"FEB\": 2, \"MAR\": 3, \"APR\": 4,  \"MAY\": 5,  \"JUN\": 6,\n",
    "    \"JUL\": 7, \"AUG\": 8, \"SEP\": 9, \"OCT\": 10, \"NOV\": 11, \"DEC\": 12,\n",
    "}\n",
    "\n",
    "MONTH_MAP_FIRST_OF: dict[str, int] = {\n",
    "    \"FIRST OF JAN\": 1, \"FIRST OF FEB\": 2, \"FIRST OF MAR\": 3, \"FIRST OF APR\": 4,\n",
    "    \"FIRST OF MAY\": 5, \"FIRST OF JUN\": 6, \"FIRST OF JUL\": 7, \"FIRST OF AUG\": 8,\n",
    "    \"FIRST OF SEP\": 9, \"FIRST OF OCT\": 10, \"FIRST OF NOV\": 11, \"FIRST OF DEC\": 12,\n",
    "}\n",
    "\n",
    "# File paths\n",
    "DATA_FOLDER = '/home/akimovh/rockets_feathers/eggs/data'  # Update as needed\n",
    "TXT_DATA_DIR = Path(DATA_FOLDER) / \"2848_txt\"\n",
    "USDA_OUTPUT_DIR = Path(DATA_FOLDER) / \"usda\"\n",
    "DUCKDB_PATH = Path(DATA_FOLDER) / \"duckdb\" / \"egg_usda.duckdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db_connection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to: /home/akimovh/rockets_feathers/eggs/data/duckdb/egg_usda.duckdb\n",
      "Threads: 40\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Database Connection\n",
    "# =============================================================================\n",
    "\n",
    "con = duckdb.connect(str(DUCKDB_PATH))\n",
    "con.execute(f\"PRAGMA threads={os.cpu_count()}\")\n",
    "print(f\"Connected to: {DUCKDB_PATH}\")\n",
    "print(f\"Threads: {os.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "utility_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Utility Functions\n",
    "# =============================================================================\n",
    "\n",
    "def fetch_nass_data(params: dict, timeout: int = 120) -> pd.DataFrame:\n",
    "    \"\"\"Fetch data from NASS QuickStats API.\"\"\"\n",
    "    response = requests.get(\n",
    "        f\"{NASS_BASE}/api_GET/\",\n",
    "        params=params,\n",
    "        timeout=timeout,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    raw_data = response.json().get(\"data\", [])\n",
    "    if not raw_data:\n",
    "        raise ValueError(\"NASS API returned empty dataset — check query parameters\")\n",
    "    \n",
    "    return pd.DataFrame(raw_data)\n",
    "\n",
    "\n",
    "def column_filter_format(df: pd.DataFrame, value_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Select and rename standard columns from NASS response.\"\"\"\n",
    "    required_cols = {\"year\", \"reference_period_desc\", \"Value\"}\n",
    "    missing = required_cols - set(df.columns)\n",
    "    if missing:\n",
    "        raise KeyError(f\"Expected columns missing from API response: {missing}\")\n",
    "    \n",
    "    return df[[\"year\", \"reference_period_desc\", \"Value\"]].rename(columns={\n",
    "        \"reference_period_desc\": \"month\",\n",
    "        \"Value\": value_name,\n",
    "    })\n",
    "\n",
    "\n",
    "def parse_value(df: pd.DataFrame, value_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Parse numeric value column, handling commas and errors.\"\"\"\n",
    "    df = df.copy()\n",
    "    df[value_name] = (\n",
    "        df[value_name]\n",
    "        .astype(str)\n",
    "        .str.replace(\",\", \"\", regex=False)\n",
    "        .pipe(pd.to_numeric, errors=\"coerce\")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def data_filter_format(df: pd.DataFrame, month_map: dict) -> pd.DataFrame:\n",
    "    \"\"\"Convert year/month columns to date and sort.\"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    df[\"month\"] = df[\"month\"].str.upper().map(month_map)\n",
    "    \n",
    "    unmapped = df[\"month\"].isna()\n",
    "    if unmapped.any():\n",
    "        bad_rows = df.loc[unmapped]\n",
    "        raise ValueError(f\"Unmapped month values:\\n{bad_rows}\")\n",
    "    \n",
    "    df[\"month\"] = df[\"month\"].astype(\"Int64\")\n",
    "    df[\"date\"] = pd.to_datetime(dict(year=df[\"year\"], month=df[\"month\"], day=1))\n",
    "    df = df.drop([\"year\", \"month\"], axis=1)\n",
    "    \n",
    "    return df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "def validate_dataframe(df: pd.DataFrame, name: str, date_col: str = \"date\") -> None:\n",
    "    \"\"\"Run basic validation checks on extracted dataframe.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Validation: {name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Rows: {len(df):,}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "    print(f\"Date range: {df[date_col].min()} → {df[date_col].max()}\")\n",
    "    print(f\"Nulls per column:\\n{df.isnull().sum()}\")\n",
    "    print(f\"Duplicates on {date_col}: {df.duplicated(subset=[date_col]).sum()}\")\n",
    "    print(f\"\\nSample (first 3 rows):\")\n",
    "    display(df.head(3))\n",
    "\n",
    "\n",
    "def save_to_db_and_csv(\n",
    "    df: pd.DataFrame, \n",
    "    table_name: str, \n",
    "    csv_filename: str,\n",
    "    con: duckdb.DuckDBPyConnection\n",
    ") -> None:\n",
    "    \"\"\"Save dataframe to DuckDB table and CSV file.\"\"\"\n",
    "    csv_path = USDA_OUTPUT_DIR / csv_filename\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    con.execute(f\"CREATE OR REPLACE TABLE {table_name} AS SELECT * FROM df\")\n",
    "    print(f\"Saved: {table_name} → {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nass_header",
   "metadata": {},
   "source": [
    "---\n",
    "# NASS Data (Feed Prices & Poultry Statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soy_header",
   "metadata": {},
   "source": [
    "## Soybean Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "soy_extract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract soybean prices\n",
    "params = {\n",
    "    \"key\":               NASS_KEY,\n",
    "    \"format\":            \"JSON\",\n",
    "    \"source_desc\":       \"SURVEY\",\n",
    "    \"sector_desc\":       \"CROPS\",\n",
    "    \"group_desc\":        \"FIELD CROPS\",\n",
    "    \"commodity_desc\":    \"SOYBEANS\",\n",
    "    \"statisticcat_desc\": \"PRICE RECEIVED\",\n",
    "    \"agg_level_desc\":    \"NATIONAL\",\n",
    "    \"freq_desc\":         \"MONTHLY\",\n",
    "    \"unit_desc\":         \"$ / BU\",\n",
    "    \"year__GE\":          1990,\n",
    "}\n",
    "\n",
    "soy_prices = fetch_nass_data(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "soy_format",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Validation: Soybean Prices\n",
      "============================================================\n",
      "Rows: 432\n",
      "Columns: ['cost_sb_us', 'date']\n",
      "Date range: 1990-01-01 00:00:00 → 2025-12-01 00:00:00\n",
      "Nulls per column:\n",
      "cost_sb_us    0\n",
      "date          0\n",
      "dtype: int64\n",
      "Duplicates on date: 0\n",
      "\n",
      "Sample (first 3 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cost_sb_us</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>207.601964</td>\n",
       "      <td>1990-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204.295030</td>\n",
       "      <td>1990-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207.601964</td>\n",
       "      <td>1990-03-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cost_sb_us       date\n",
       "0  207.601964 1990-01-01\n",
       "1  204.295030 1990-02-01\n",
       "2  207.601964 1990-03-01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Format soybean prices\n",
    "soy_prices = column_filter_format(soy_prices, \"cost_sb_us\")\n",
    "soy_prices = parse_value(soy_prices, \"cost_sb_us\")\n",
    "soy_prices = data_filter_format(soy_prices, MONTH_MAP)\n",
    "\n",
    "# Convert $/bushel to $/metric ton\n",
    "soy_prices[\"cost_sb_us\"] = soy_prices[\"cost_sb_us\"] * BUSHELS_PER_METRIC_TON_SOY\n",
    "\n",
    "# Validate\n",
    "validate_dataframe(soy_prices, \"Soybean Prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "soy_save",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: COST_SB_US_MONTHLY → /home/akimovh/rockets_feathers/eggs/data/usda/cost_sb_us_monthly.csv\n"
     ]
    }
   ],
   "source": [
    "# Save soybean prices\n",
    "save_to_db_and_csv(soy_prices, \"COST_SB_US_MONTHLY\", \"cost_sb_us_monthly.csv\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corn_header",
   "metadata": {},
   "source": [
    "## Corn Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "corn_extract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract corn prices\n",
    "params = {\n",
    "    \"key\":               NASS_KEY,\n",
    "    \"format\":            \"JSON\",\n",
    "    \"source_desc\":       \"SURVEY\",\n",
    "    \"sector_desc\":       \"CROPS\",\n",
    "    \"group_desc\":        \"FIELD CROPS\",\n",
    "    \"commodity_desc\":    \"CORN\",\n",
    "    \"statisticcat_desc\": \"PRICE RECEIVED\",\n",
    "    \"agg_level_desc\":    \"NATIONAL\",\n",
    "    \"freq_desc\":         \"MONTHLY\",\n",
    "    \"unit_desc\":         \"$ / BU\",\n",
    "    \"year__GE\":          1990,\n",
    "}\n",
    "\n",
    "corn_prices = fetch_nass_data(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "corn_format",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Validation: Corn Prices\n",
      "============================================================\n",
      "Rows: 432\n",
      "Columns: ['cost_corn_us', 'date']\n",
      "Date range: 1990-01-01 00:00:00 → 2025-12-01 00:00:00\n",
      "Nulls per column:\n",
      "cost_corn_us    0\n",
      "date            0\n",
      "dtype: int64\n",
      "Duplicates on date: 0\n",
      "\n",
      "Sample (first 3 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cost_corn_us</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.940683</td>\n",
       "      <td>1990-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91.334366</td>\n",
       "      <td>1990-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93.302779</td>\n",
       "      <td>1990-03-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cost_corn_us       date\n",
       "0     90.940683 1990-01-01\n",
       "1     91.334366 1990-02-01\n",
       "2     93.302779 1990-03-01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Format corn prices\n",
    "corn_prices = column_filter_format(corn_prices, \"cost_corn_us\")\n",
    "corn_prices = parse_value(corn_prices, \"cost_corn_us\")\n",
    "corn_prices = data_filter_format(corn_prices, MONTH_MAP)\n",
    "\n",
    "# Convert $/bushel to $/metric ton\n",
    "corn_prices[\"cost_corn_us\"] = corn_prices[\"cost_corn_us\"] * BUSHELS_PER_METRIC_TON_CORN\n",
    "\n",
    "# Validate\n",
    "validate_dataframe(corn_prices, \"Corn Prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "corn_save",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: COST_CORN_US_MONTHLY → /home/akimovh/rockets_feathers/eggs/data/usda/cost_corn_us_monthly.csv\n"
     ]
    }
   ],
   "source": [
    "# Save corn prices\n",
    "save_to_db_and_csv(corn_prices, \"COST_CORN_US_MONTHLY\", \"cost_corn_us_monthly.csv\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egg_prod_header",
   "metadata": {},
   "source": [
    "## Egg Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "egg_prod_extract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract egg production data\n",
    "params = {\n",
    "    \"key\":          NASS_KEY,\n",
    "    \"format\":       \"JSON\",\n",
    "    \"source_desc\":  \"SURVEY\",\n",
    "    \"sector_desc\":  \"ANIMALS & PRODUCTS\",\n",
    "    \"group_desc\":   \"POULTRY\",\n",
    "    \"commodity_desc\": \"EGGS\",\n",
    "    \"short_desc\":   \"EGGS, TABLE - PRODUCTION, MEASURED IN DOZEN\",\n",
    "    \"agg_level_desc\": \"NATIONAL\",\n",
    "    \"freq_desc\":    \"MONTHLY\",\n",
    "    \"year__GE\":     2000,\n",
    "}\n",
    "\n",
    "egg_prod_doz = fetch_nass_data(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "egg_prod_format",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Validation: Egg Production\n",
      "============================================================\n",
      "Rows: 157\n",
      "Columns: ['egg_prod_doz', 'date']\n",
      "Date range: 2012-12-01 00:00:00 → 2025-12-01 00:00:00\n",
      "Nulls per column:\n",
      "egg_prod_doz    0\n",
      "date            0\n",
      "dtype: int64\n",
      "Duplicates on date: 0\n",
      "\n",
      "Sample (first 3 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>egg_prod_doz</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>606807900</td>\n",
       "      <td>2012-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>599733800</td>\n",
       "      <td>2013-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>540083400</td>\n",
       "      <td>2013-02-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   egg_prod_doz       date\n",
       "0     606807900 2012-12-01\n",
       "1     599733800 2013-01-01\n",
       "2     540083400 2013-02-01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Format egg production data\n",
    "egg_prod_doz = column_filter_format(egg_prod_doz, \"egg_prod_doz\")\n",
    "egg_prod_doz = parse_value(egg_prod_doz, \"egg_prod_doz\")\n",
    "egg_prod_doz = data_filter_format(egg_prod_doz, MONTH_MAP)\n",
    "\n",
    "# Validate\n",
    "validate_dataframe(egg_prod_doz, \"Egg Production\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "egg_prod_save",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: EGG_PROD_DOZ_MONTHLY → /home/akimovh/rockets_feathers/eggs/data/usda/egg_prod_doz_monthly.csv\n"
     ]
    }
   ],
   "source": [
    "# Save egg production\n",
    "save_to_db_and_csv(egg_prod_doz, \"EGG_PROD_DOZ_MONTHLY\", \"egg_prod_doz_monthly.csv\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "layer_inv_header",
   "metadata": {},
   "source": [
    "## Layer Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "layer_inv_extract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract layer inventory data\n",
    "params = {\n",
    "    \"key\":               NASS_KEY,\n",
    "    \"format\":            \"JSON\",\n",
    "    \"source_desc\":       \"SURVEY\",\n",
    "    \"sector_desc\":       \"ANIMALS & PRODUCTS\",\n",
    "    \"group_desc\":        \"POULTRY\",\n",
    "    \"commodity_desc\":    \"CHICKENS\",\n",
    "    \"statisticcat_desc\": \"INVENTORY\",\n",
    "    \"class_desc\":        \"LAYERS, TABLE\",\n",
    "    \"agg_level_desc\":    \"NATIONAL\",\n",
    "    \"year__GE\":          2000,\n",
    "}\n",
    "\n",
    "layer_inv = fetch_nass_data(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "layer_inv_format",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Validation: Layer Inventory\n",
      "============================================================\n",
      "Rows: 217\n",
      "Columns: ['layer_inv', 'date']\n",
      "Date range: 2008-01-01 00:00:00 → 2026-01-01 00:00:00\n",
      "Nulls per column:\n",
      "layer_inv    0\n",
      "date         0\n",
      "dtype: int64\n",
      "Duplicates on date: 0\n",
      "\n",
      "Sample (first 3 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_inv</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>284729000</td>\n",
       "      <td>2008-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282437000</td>\n",
       "      <td>2008-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>281404000</td>\n",
       "      <td>2008-03-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   layer_inv       date\n",
       "0  284729000 2008-01-01\n",
       "1  282437000 2008-02-01\n",
       "2  281404000 2008-03-01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Format layer inventory data (uses \"FIRST OF\" month format)\n",
    "layer_inv = column_filter_format(layer_inv, \"layer_inv\")\n",
    "layer_inv = parse_value(layer_inv, \"layer_inv\")\n",
    "layer_inv = data_filter_format(layer_inv, MONTH_MAP_FIRST_OF)\n",
    "\n",
    "# Validate\n",
    "validate_dataframe(layer_inv, \"Layer Inventory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "layer_inv_save",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: LAYER_INV_MONTHLY → /home/akimovh/rockets_feathers/eggs/data/usda/layer_inv_monthly.csv\n"
     ]
    }
   ],
   "source": [
    "# Save layer inventory\n",
    "save_to_db_and_csv(layer_inv, \"LAYER_INV_MONTHLY\", \"layer_inv_monthly.csv\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "layer_loss_header",
   "metadata": {},
   "source": [
    "## Layer Losses (Death & Rendered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "layer_loss_extract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract layer loss data\n",
    "params = {\n",
    "    \"key\":               NASS_KEY,\n",
    "    \"format\":            \"JSON\",\n",
    "    \"source_desc\":       \"SURVEY\",\n",
    "    \"sector_desc\":       \"ANIMALS & PRODUCTS\",\n",
    "    \"group_desc\":        \"POULTRY\",\n",
    "    \"commodity_desc\":    \"CHICKENS\",\n",
    "    \"statisticcat_desc\": \"LOSS, DEATH & RENDERED\",\n",
    "    \"class_desc\":        \"LAYERS\",\n",
    "    \"unit_desc\":         \"HEAD\",\n",
    "    \"agg_level_desc\":    \"NATIONAL\",\n",
    "    \"freq_desc\":         \"MONTHLY\",\n",
    "    \"year__GE\":          2000,\n",
    "}\n",
    "\n",
    "loss_dth_render = fetch_nass_data(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "layer_loss_format",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Validation: Layer Losses\n",
      "============================================================\n",
      "Rows: 217\n",
      "Columns: ['loss_dth_render', 'date']\n",
      "Date range: 2007-12-01 00:00:00 → 2025-12-01 00:00:00\n",
      "Nulls per column:\n",
      "loss_dth_render    0\n",
      "date               0\n",
      "dtype: int64\n",
      "Duplicates on date: 0\n",
      "\n",
      "Sample (first 3 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_dth_render</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7501000</td>\n",
       "      <td>2007-12-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7422000</td>\n",
       "      <td>2008-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7370000</td>\n",
       "      <td>2008-02-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss_dth_render       date\n",
       "0          7501000 2007-12-01\n",
       "1          7422000 2008-01-01\n",
       "2          7370000 2008-02-01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Format layer loss data\n",
    "loss_dth_render = column_filter_format(loss_dth_render, \"loss_dth_render\")\n",
    "loss_dth_render = parse_value(loss_dth_render, \"loss_dth_render\")\n",
    "loss_dth_render = data_filter_format(loss_dth_render, MONTH_MAP)\n",
    "\n",
    "# Validate\n",
    "validate_dataframe(loss_dth_render, \"Layer Losses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "layer_loss_save",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: LOSS_DTH_RENDER_MONTHLY → /home/akimovh/rockets_feathers/eggs/data/usda/loss_dth_render_monthly.csv\n"
     ]
    }
   ],
   "source": [
    "# Save layer losses\n",
    "save_to_db_and_csv(loss_dth_render, \"LOSS_DTH_RENDER_MONTHLY\", \"loss_dth_render_monthly.csv\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ams_header",
   "metadata": {},
   "source": [
    "---\n",
    "# AMS Data (Wholesale Egg Prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ams_old_header",
   "metadata": {},
   "source": [
    "## Historical Data (TXT files from MMN archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ams_old_parse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 378 files\n",
      "Total rows: 1,890\n",
      "Files with errors: 0\n"
     ]
    }
   ],
   "source": [
    "# Parse historical TXT files\n",
    "\n",
    "HEADER_RE = re.compile(\n",
    "    r\"^Washington,\\s*DC\\s+(?P<date>(?:Mon|Tue|Wed|Thu|Fri|Sat|Sun)\\.\\s+\"\n",
    "    r\"(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s+\\d{1,2},\\s+\\d{4})\\s+\"\n",
    "    r\"USDA\\s+Market\\s+News\\s*$\"\n",
    ")\n",
    "\n",
    "\n",
    "def parse_one_file(fp: Path) -> pd.DataFrame:\n",
    "    \"\"\"Parse a single USDA Market News TXT file.\"\"\"\n",
    "    text = fp.read_text(encoding=\"latin-1\", errors=\"replace\")\n",
    "    lines = text.splitlines()\n",
    "\n",
    "    # Extract date from header line\n",
    "    date_str = next(\n",
    "        HEADER_RE.match(line.strip()).group(\"date\")\n",
    "        for line in lines if HEADER_RE.match(line.strip())\n",
    "    )\n",
    "    date = pd.to_datetime(date_str, format=\"%a. %b %d, %Y\").normalize()\n",
    "\n",
    "    # Find table start (line after \"REGIONS ...\")\n",
    "    start = next(i for i, line in enumerate(lines) if line.strip().startswith(\"REGIONS\")) + 1\n",
    "\n",
    "    # Collect data rows until footer\n",
    "    rows = []\n",
    "    for line in lines[start:]:\n",
    "        s = line.strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        if s.startswith((\"Computed\", \"Source:\", \"Prepared:\")):\n",
    "            break\n",
    "\n",
    "        parts = s.split()\n",
    "        if len(parts) < 4:\n",
    "            continue\n",
    "\n",
    "        region = \" \".join(parts[:-3])\n",
    "        ex_large, large, medium = map(float, parts[-3:])\n",
    "        rows.append({\n",
    "            \"date\": date,\n",
    "            \"region\": region,\n",
    "            \"ex_large\": ex_large,\n",
    "            \"large\": large,\n",
    "            \"medium\": medium,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# Parse all TXT files\n",
    "files = sorted([p for p in TXT_DATA_DIR.iterdir() if p.is_file() and p.suffix.lower() == \".txt\"])\n",
    "\n",
    "dfs = []\n",
    "errors = []\n",
    "\n",
    "for fp in files:\n",
    "    try:\n",
    "        dfs.append(parse_one_file(fp))\n",
    "    except Exception as e:\n",
    "        errors.append((fp.name, str(e)))\n",
    "\n",
    "txt_df = pd.concat(dfs, ignore_index=True).sort_values([\"date\", \"region\"]).reset_index(drop=True)\n",
    "\n",
    "print(f\"Parsed {len(files)} files\")\n",
    "print(f\"Total rows: {len(txt_df):,}\")\n",
    "print(f\"Files with errors: {len(errors)}\")\n",
    "if errors:\n",
    "    display(pd.DataFrame(errors, columns=[\"file\", \"error\"]).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ams_old_normalize",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate (week_fri, region) rows: 0\n",
      "Date range: 2017-11-03 → 2025-01-24\n",
      "Unique weeks: 378\n",
      "Expected weeks: 378\n",
      "Missing weeks: 0\n",
      "Extra weeks: 0\n",
      "\n",
      "Dates adjusted to nearest Friday: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>week_fri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-11-09</td>\n",
       "      <td>2017-11-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>2019-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>2019-08-19</td>\n",
       "      <td>2019-08-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>2020-07-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>2021-12-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>2022-11-10</td>\n",
       "      <td>2022-11-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   week_fri\n",
       "5    2017-11-09 2017-11-10\n",
       "390  2019-05-06 2019-05-03\n",
       "465  2019-08-19 2019-08-16\n",
       "695  2020-07-02 2020-07-03\n",
       "825  2020-12-31 2021-01-01\n",
       "1080 2021-12-23 2021-12-24\n",
       "1085 2021-12-30 2021-12-31\n",
       "1310 2022-11-10 2022-11-11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalize dates to week-ending Friday\n",
    "# Some reports are published on different days due to holidays\n",
    "\n",
    "txt_df[\"date\"] = pd.to_datetime(txt_df[\"date\"]).dt.normalize()\n",
    "fri = pd.offsets.Week(weekday=4)  # Friday\n",
    "\n",
    "\n",
    "def week_end_friday(d: pd.Timestamp) -> pd.Timestamp:\n",
    "    \"\"\"Map date to nearest Friday (week-ending date).\"\"\"\n",
    "    prev_fri = fri.rollback(d)\n",
    "    next_fri = fri.rollforward(d)\n",
    "    return prev_fri if (d - prev_fri) <= (next_fri - d) else next_fri\n",
    "\n",
    "\n",
    "txt_df[\"week_fri\"] = txt_df[\"date\"].apply(week_end_friday)\n",
    "\n",
    "# Validation checks\n",
    "dup = txt_df.duplicated([\"week_fri\", \"region\"]).sum()\n",
    "print(f\"Duplicate (week_fri, region) rows: {dup}\")\n",
    "\n",
    "dates = pd.DatetimeIndex(sorted(txt_df[\"week_fri\"].unique()))\n",
    "expected = pd.date_range(dates.min(), dates.max(), freq=\"W-FRI\")\n",
    "\n",
    "missing = expected.difference(dates)\n",
    "extra = dates.difference(expected)\n",
    "\n",
    "print(f\"Date range: {dates.min().date()} → {dates.max().date()}\")\n",
    "print(f\"Unique weeks: {len(dates)}\")\n",
    "print(f\"Expected weeks: {len(expected)}\")\n",
    "print(f\"Missing weeks: {len(missing)}\")\n",
    "print(f\"Extra weeks: {len(extra)}\")\n",
    "\n",
    "# Show dates that were adjusted\n",
    "moved = (\n",
    "    txt_df.loc[txt_df[\"date\"] != txt_df[\"week_fri\"], [\"date\", \"week_fri\"]]\n",
    "    .drop_duplicates()\n",
    "    .sort_values(\"date\")\n",
    ")\n",
    "print(f\"\\nDates adjusted to nearest Friday: {len(moved)}\")\n",
    "display(moved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ams_old_finalize",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regions: ['National', 'Midwest', 'Northeast', 'South Central', 'Southeast']\n"
     ]
    }
   ],
   "source": [
    "# Finalize historical data\n",
    "txt_df[\"date\"] = txt_df[\"week_fri\"]\n",
    "txt_df = txt_df.drop(\"week_fri\", axis=1).copy()\n",
    "\n",
    "# Standardize region names\n",
    "REGION_MAP = {\n",
    "    \"COMBINED REGIONAL\": \"National\",\n",
    "    \"MIDWEST\": \"Midwest\",\n",
    "    \"NORTHEAST\": \"Northeast\",\n",
    "    \"SOUTH CENTRAL\": \"South Central\",\n",
    "    \"SOUTHEAST\": \"Southeast\",\n",
    "}\n",
    "txt_df[\"region\"] = txt_df[\"region\"].map(REGION_MAP)\n",
    "\n",
    "print(f\"Regions: {txt_df['region'].unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ams_new_header",
   "metadata": {},
   "source": [
    "## Recent Data (JSON via AMS API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ams_new_extract",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200\n",
      "URL: https://marsapi.ams.usda.gov/services/v1.2/reports/2848?q=report_begin_date%3D01%2F20%2F2025%3A02%2F02%2F2026&allSections=true\n",
      "Raw rows from API: 1,113\n"
     ]
    }
   ],
   "source": [
    "# Fetch recent data from AMS API\n",
    "\n",
    "SLUG = 2848  # Report ID for shell egg prices\n",
    "start = \"01/20/2025\"  # Start after TXT data ends\n",
    "end = pd.Timestamp.today().strftime(\"%m/%d/%Y\")\n",
    "\n",
    "response = requests.get(\n",
    "    f\"{AMS_BASE}/reports/{SLUG}\",\n",
    "    params={\"q\": f\"report_begin_date={start}:{end}\", \"allSections\": \"true\"},\n",
    "    auth=(AMS_KEY, \"\"),\n",
    "    timeout=120,\n",
    ")\n",
    "print(f\"Status: {response.status_code}\")\n",
    "print(f\"URL: {response.url}\")\n",
    "response.raise_for_status()\n",
    "\n",
    "rep_range = response.json()\n",
    "api_df = pd.DataFrame(rep_range[4][\"results\"])\n",
    "print(f\"Raw rows from API: {len(api_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ams_new_format",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted API rows: 265\n",
      "Date range: 2025-01-31 → 2026-01-30\n"
     ]
    }
   ],
   "source": [
    "# Format API data to match historical format\n",
    "\n",
    "api_df = api_df.query(\n",
    "    \"`class` in ['Extra Large', 'Large', 'Medium'] and delivery == 'Delivered Warehouse'\"\n",
    ")\n",
    "api_df = api_df[[\"report_begin_date\", \"class\", \"region\", \"avg_price\"]]\n",
    "\n",
    "api_df = (\n",
    "    api_df\n",
    "    .pivot(\n",
    "        index=[\"report_begin_date\", \"region\"],\n",
    "        columns=\"class\",\n",
    "        values=\"avg_price\",\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Match column names to TXT data\n",
    "api_df.columns = txt_df.columns\n",
    "\n",
    "# Parse and normalize dates to Friday\n",
    "api_df[\"date\"] = pd.to_datetime(api_df[\"date\"], format=\"%m/%d/%Y\").dt.normalize()\n",
    "api_df[\"date\"] = api_df[\"date\"].map(fri.rollforward)\n",
    "\n",
    "# Ensure numeric types\n",
    "api_df[\"ex_large\"] = api_df[\"ex_large\"].astype(float)\n",
    "api_df[\"large\"] = api_df[\"large\"].astype(float)\n",
    "api_df[\"medium\"] = api_df[\"medium\"].astype(float)\n",
    "\n",
    "print(f\"Formatted API rows: {len(api_df):,}\")\n",
    "print(f\"Date range: {api_df['date'].min().date()} → {api_df['date'].max().date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ams_combine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Validation: Wholesale Prices (Weekly)\n",
      "============================================================\n",
      "Rows: 2,155\n",
      "Columns: ['date', 'region', 'ex_large', 'large', 'medium']\n",
      "Date range: 2017-11-03 00:00:00 → 2026-01-30 00:00:00\n",
      "Nulls per column:\n",
      "date        0\n",
      "region      0\n",
      "ex_large    0\n",
      "large       0\n",
      "medium      0\n",
      "dtype: int64\n",
      "Duplicates on date: 1724\n",
      "\n",
      "Sample (first 3 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>region</th>\n",
       "      <th>ex_large</th>\n",
       "      <th>large</th>\n",
       "      <th>medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-11-03</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>90.50</td>\n",
       "      <td>88.50</td>\n",
       "      <td>74.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-11-03</td>\n",
       "      <td>National</td>\n",
       "      <td>101.33</td>\n",
       "      <td>96.29</td>\n",
       "      <td>79.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-11-03</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>99.00</td>\n",
       "      <td>94.00</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date     region  ex_large  large  medium\n",
       "0 2017-11-03    Midwest     90.50  88.50   74.50\n",
       "1 2017-11-03   National    101.33  96.29   79.15\n",
       "2 2017-11-03  Northeast     99.00  94.00   80.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicates on (date, region): 0\n"
     ]
    }
   ],
   "source": [
    "# Combine historical and recent data\n",
    "wholesale_price = (\n",
    "    pd.concat([txt_df, api_df])\n",
    "    .sort_values([\"date\", \"region\"])\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Validate combined data\n",
    "validate_dataframe(wholesale_price, \"Wholesale Prices (Weekly)\")\n",
    "\n",
    "# Check for duplicates on primary key\n",
    "dup_check = wholesale_price.duplicated(subset=[\"date\", \"region\"]).sum()\n",
    "print(f\"\\nDuplicates on (date, region): {dup_check}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ams_save_weekly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: WHOLESALE_PRICE_WEEKLY → /home/akimovh/rockets_feathers/eggs/data/usda/wholesale_price_weekly.csv\n"
     ]
    }
   ],
   "source": [
    "# Save weekly wholesale prices\n",
    "save_to_db_and_csv(wholesale_price, \"WHOLESALE_PRICE_WEEKLY\", \"wholesale_price_weekly.csv\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly_agg_header",
   "metadata": {},
   "source": [
    "## Aggregate to Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ams_monthly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Validation: Wholesale Prices (Monthly)\n",
      "============================================================\n",
      "Rows: 500\n",
      "Columns: ['date', 'region', 'price_ex_large', 'price_large', 'price_medium']\n",
      "Date range: 2017-10-01 00:00:00 → 2026-01-01 00:00:00\n",
      "Nulls per column:\n",
      "date              0\n",
      "region            0\n",
      "price_ex_large    0\n",
      "price_large       0\n",
      "price_medium      0\n",
      "dtype: int64\n",
      "Duplicates on date: 400\n",
      "\n",
      "Sample (first 3 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>region</th>\n",
       "      <th>price_ex_large</th>\n",
       "      <th>price_large</th>\n",
       "      <th>price_medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>Midwest</td>\n",
       "      <td>90.50</td>\n",
       "      <td>88.50</td>\n",
       "      <td>74.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>National</td>\n",
       "      <td>101.33</td>\n",
       "      <td>96.29</td>\n",
       "      <td>79.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>99.00</td>\n",
       "      <td>94.00</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date     region  price_ex_large  price_large  price_medium\n",
       "0 2017-10-01    Midwest           90.50        88.50         74.50\n",
       "1 2017-10-01   National          101.33        96.29         79.15\n",
       "2 2017-10-01  Northeast           99.00        94.00         80.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aggregate weekly prices to monthly averages\n",
    "# Expand each week to daily observations, then average by month\n",
    "\n",
    "df_weekly = wholesale_price.copy()\n",
    "df_weekly[\"week_start\"] = df_weekly[\"date\"] - pd.Timedelta(days=6)\n",
    "df_weekly[\"week_end\"] = df_weekly[\"date\"]\n",
    "\n",
    "\n",
    "def expand_week_to_months(row):\n",
    "    \"\"\"Expand a week's prices to daily observations for proper monthly averaging.\"\"\"\n",
    "    dates = pd.date_range(row.week_start, row.week_end, freq=\"D\")\n",
    "    return pd.DataFrame({\n",
    "        \"date\": dates,\n",
    "        \"month\": dates.to_period(\"M\").to_timestamp(),\n",
    "        \"price_ex_large\": row.ex_large,\n",
    "        \"price_large\": row.large,\n",
    "        \"price_medium\": row.medium,\n",
    "        \"region\": row.region,\n",
    "    })\n",
    "\n",
    "\n",
    "expanded_df = pd.concat(\n",
    "    df_weekly.apply(expand_week_to_months, axis=1).tolist(),\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "monthly_df = (\n",
    "    expanded_df\n",
    "    .groupby([\"month\", \"region\"], as_index=False)\n",
    "    .agg({\n",
    "        \"price_ex_large\": \"mean\",\n",
    "        \"price_large\": \"mean\",\n",
    "        \"price_medium\": \"mean\",\n",
    "    })\n",
    ")\n",
    "monthly_df.columns = [\"date\", \"region\", \"price_ex_large\", \"price_large\", \"price_medium\"]\n",
    "\n",
    "# Validate\n",
    "validate_dataframe(monthly_df, \"Wholesale Prices (Monthly)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ams_save_monthly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: WHOLESALE_PRICE_MONTHLY → /home/akimovh/rockets_feathers/eggs/data/usda/wholesale_price_monthly.csv\n"
     ]
    }
   ],
   "source": [
    "# Save monthly wholesale prices\n",
    "save_to_db_and_csv(monthly_df, \"WHOLESALE_PRICE_MONTHLY\", \"wholesale_price_monthly.csv\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined_header",
   "metadata": {},
   "source": [
    "---\n",
    "# Combined Monthly Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "combine_all",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Validation: Combined Egg Statistics (Monthly)\n",
      "============================================================\n",
      "Rows: 93\n",
      "Columns: ['cost_sb_us', 'date', 'cost_corn_us', 'egg_prod_doz', 'layer_inv', 'loss_dth_render', 'price_ex_large', 'price_large', 'price_medium']\n",
      "Date range: 2018-01-01 00:00:00 → 2025-09-01 00:00:00\n",
      "Nulls per column:\n",
      "cost_sb_us         0\n",
      "date               0\n",
      "cost_corn_us       0\n",
      "egg_prod_doz       0\n",
      "layer_inv          0\n",
      "loss_dth_render    0\n",
      "price_ex_large     0\n",
      "price_large        0\n",
      "price_medium       0\n",
      "dtype: int64\n",
      "Duplicates on date: 0\n",
      "\n",
      "Sample (first 3 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cost_sb_us</th>\n",
       "      <th>date</th>\n",
       "      <th>cost_corn_us</th>\n",
       "      <th>egg_prod_doz</th>\n",
       "      <th>layer_inv</th>\n",
       "      <th>loss_dth_render</th>\n",
       "      <th>price_ex_large</th>\n",
       "      <th>price_large</th>\n",
       "      <th>price_medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>341.716506</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>129.521579</td>\n",
       "      <td>670016600</td>\n",
       "      <td>329809000</td>\n",
       "      <td>10175700</td>\n",
       "      <td>127.786129</td>\n",
       "      <td>125.011290</td>\n",
       "      <td>100.276774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>349.065248</td>\n",
       "      <td>2018-02-01</td>\n",
       "      <td>133.064723</td>\n",
       "      <td>607308600</td>\n",
       "      <td>329125000</td>\n",
       "      <td>10202100</td>\n",
       "      <td>161.273929</td>\n",
       "      <td>159.872143</td>\n",
       "      <td>118.452857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>360.455799</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>138.182596</td>\n",
       "      <td>677992000</td>\n",
       "      <td>333188000</td>\n",
       "      <td>10482800</td>\n",
       "      <td>222.170000</td>\n",
       "      <td>220.675484</td>\n",
       "      <td>132.794194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cost_sb_us       date  cost_corn_us  egg_prod_doz  layer_inv  \\\n",
       "3  341.716506 2018-01-01    129.521579     670016600  329809000   \n",
       "4  349.065248 2018-02-01    133.064723     607308600  329125000   \n",
       "5  360.455799 2018-03-01    138.182596     677992000  333188000   \n",
       "\n",
       "   loss_dth_render  price_ex_large  price_large  price_medium  \n",
       "3         10175700      127.786129   125.011290    100.276774  \n",
       "4         10202100      161.273929   159.872143    118.452857  \n",
       "5         10482800      222.170000   220.675484    132.794194  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Merge all monthly datasets\n",
    "\n",
    "dfs_to_merge = [\n",
    "    soy_prices,\n",
    "    corn_prices,\n",
    "    egg_prod_doz,\n",
    "    layer_inv,\n",
    "    loss_dth_render,\n",
    "    monthly_df.query(\"region == 'National'\").drop(columns=[\"region\"]),  # National prices only\n",
    "]\n",
    "\n",
    "egg_stat = reduce(\n",
    "    lambda left, right: pd.merge(left, right, on=\"date\", how=\"inner\"),\n",
    "    dfs_to_merge,\n",
    ")\n",
    "\n",
    "# Filter to analysis period\n",
    "egg_stat = egg_stat.query(\"date >= '2018-01-01' and date < '2025-10-01'\").copy()\n",
    "\n",
    "# Validate\n",
    "validate_dataframe(egg_stat, \"Combined Egg Statistics (Monthly)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "save_combined",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: EGG_STAT_MONTHLY → /home/akimovh/rockets_feathers/eggs/data/usda/egg_stat_monthly.csv\n"
     ]
    }
   ],
   "source": [
    "# Save combined dataset\n",
    "save_to_db_and_csv(egg_stat, \"EGG_STAT_MONTHLY\", \"egg_stat_monthly.csv\", con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e87dbe4",
   "metadata": {},
   "source": [
    "### Flu outbreak data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dbaff5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: FLU_WEEKLY → /home/akimovh/rockets_feathers/eggs/data/usda/flu_weekly.csv\n"
     ]
    }
   ],
   "source": [
    "flu = pd.read_csv('/home/akimovh/rockets_feathers/eggs/data/usda/flu.csv')\n",
    "flu.columns = ['date', 'state', 'value']\n",
    "flu = flu.groupby(by = 'date', as_index = False).value.sum()\n",
    "flu['date'] = pd.to_datetime(flu['date'])\n",
    "flu_weekly = (\n",
    "    flu\n",
    "    .set_index('date')\n",
    "    .resample('W-SAT', label='right', closed='right')\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "save_to_db_and_csv(flu_weekly, \"FLU_WEEKLY\", \"flu_weekly.csv\", con)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_check_header",
   "metadata": {},
   "source": [
    "---\n",
    "# Final Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "final_check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in database:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COST_CORN_US_MONTHLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COST_SB_US_MONTHLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EGG_PROD_DOZ_MONTHLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EGG_STAT_MONTHLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LAYER_INV_MONTHLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LOSS_DTH_RENDER_MONTHLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WHOLESALE_PRICE_MONTHLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WHOLESALE_PRICE_WEEKLY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name\n",
       "0     COST_CORN_US_MONTHLY\n",
       "1       COST_SB_US_MONTHLY\n",
       "2     EGG_PROD_DOZ_MONTHLY\n",
       "3         EGG_STAT_MONTHLY\n",
       "4        LAYER_INV_MONTHLY\n",
       "5  LOSS_DTH_RENDER_MONTHLY\n",
       "6  WHOLESALE_PRICE_MONTHLY\n",
       "7   WHOLESALE_PRICE_WEEKLY"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row counts:\n",
      "  COST_CORN_US_MONTHLY: 432\n",
      "  COST_SB_US_MONTHLY: 432\n",
      "  EGG_PROD_DOZ_MONTHLY: 157\n",
      "  EGG_STAT_MONTHLY: 93\n",
      "  LAYER_INV_MONTHLY: 217\n",
      "  LOSS_DTH_RENDER_MONTHLY: 217\n",
      "  WHOLESALE_PRICE_MONTHLY: 500\n",
      "  WHOLESALE_PRICE_WEEKLY: 2,155\n"
     ]
    }
   ],
   "source": [
    "# List all tables created\n",
    "print(\"Tables in database:\")\n",
    "display(con.execute(\"SHOW TABLES\").df())\n",
    "\n",
    "# Quick row counts\n",
    "print(\"\\nRow counts:\")\n",
    "tables = con.execute(\"SHOW TABLES\").df()[\"name\"].tolist()\n",
    "for table in tables:\n",
    "    count = con.execute(f\"SELECT COUNT(*) as n FROM {table}\").fetchone()[0]\n",
    "    print(f\"  {table}: {count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "close_connection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "# Close database connection\n",
    "con.close()\n",
    "print(\"Database connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b438811c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
